{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('mark1': conda)"
  },
  "interpreter": {
   "hash": "842e6a94f7b00bd88c2d2a2fc81dcd9f0ee99928f96e0f860dbda703cd7a4701"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from keras.preprocessing.image import smart_resize, load_img, img_to_array, array_to_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the path\n",
    "train_path = '/media/charchit/New Volume/DataSet/Cat_Dog_data/train/'\n",
    "test_path = '/media/charchit/New Volume/DataSet/Cat_Dog_data/test/'\n",
    "\n",
    "#set the default size\n",
    "size = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDS(path, resize_size, testds=False):\n",
    "    \n",
    "    dataset = []\n",
    "    labels = []\n",
    "    total_classes = os.listdir(path)\n",
    "    total_classes.remove('.DS_Store')\n",
    "\n",
    "    for category in total_classes:\n",
    "        category_path = os.path.join(path,category)\n",
    "        total_images = os.listdir(category_path)\n",
    "        \n",
    "        #to reduce load on ram\n",
    "        if testds==True:\n",
    "            images = total_images[:50]\n",
    "        else:\n",
    "            images = total_images[:200]\n",
    "\n",
    "        for image in images:\n",
    "            img_path = os.path.join(category_path,image)\n",
    "            a = load_img(img_path)\n",
    "            #to convert to numpy arr\n",
    "            b = img_to_array(a)\n",
    "            #resize the array as required size\n",
    "            c = smart_resize(b,size)\n",
    "\n",
    "            if image.split('.')[0].lower() == 'cat':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "            dataset.append(c)\n",
    "            # labels.append(label)\n",
    "\n",
    "            #convert whole ds to np array\n",
    "            dataset_final = np.array(dataset)\n",
    "            label_final = np.array(labels)\n",
    "    \n",
    "    return dataset_final, label_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "# 1. flatten image\n",
    "# 2. standardize\n",
    "def preprocessing(train_ds, test_ds):\n",
    "    train_ds_flatten = train_ds.reshape(train_ds.shape[0],-1).T\n",
    "    test_ds_flatten = test_ds.reshape(test_ds.shape[0],-1).T\n",
    "    #standardize the dataset, subtract mean of whole array from each other.\n",
    "    #easy in images we can divide with 255\n",
    "    train_set_x = train_ds_flatten/255.\n",
    "    test_set_x = test_ds_flatten/255.\n",
    "\n",
    "    return train_set_x, test_set_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds, train_label = CreateDS(train_path, size)\n",
    "test_ds, test_label = CreateDS(test_path,size, testds=True)\n",
    "train_label = train_label.reshape(1,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((400, 200, 200, 3), (1, 400))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_ds.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 200, 200, 3), (1, 100))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#50 for dog, 50 for cat\n",
    "test_label = test_label.reshape(1,100)\n",
    "test_ds.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = preprocessing(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle images and dataset, will be done after image resizing!\n",
    "def shuffle(length,ds,lbl):\n",
    "    perm = list(np.random.permutation(length))\n",
    "    shuffled_ds = ds[:,perm]\n",
    "    shuffled_lbl = lbl[:,perm].reshape((1,length))\n",
    "    return shuffled_ds, shuffled_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((120000, 400), (120000, 100))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = shuffle(400,train_set,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120000, 400)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d = shuffle(100,test_set, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((120000, 100), (1, 100))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "c.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture import sigmoid, optimize, predict, propagate, initialize_with_zeros, logisticregressionmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost after 0:0.693147\n",
      "cost after 100:0.687682\n",
      "cost after 200:0.682996\n",
      "cost after 300:0.678852\n",
      "cost after 400:0.675107\n",
      "cost after 500:0.671664\n",
      "cost after 600:0.668456\n",
      "cost after 700:0.665434\n",
      "cost after 800:0.662566\n",
      "cost after 900:0.659825\n",
      "cost after 1000:0.657193\n",
      "cost after 1100:0.654656\n",
      "cost after 1200:0.652203\n",
      "cost after 1300:0.649826\n",
      "cost after 1400:0.647517\n",
      "cost after 1500:0.645269\n",
      "cost after 1600:0.643080\n",
      "cost after 1700:0.640943\n",
      "cost after 1800:0.638855\n",
      "cost after 1900:0.636814\n",
      "train accuracy: 69.25 %\n",
      "test accuracy: 56.0 %\n"
     ]
    }
   ],
   "source": [
    "a = a.astype(float)\n",
    "c = c.astype(float)\n",
    "logistic_regression_model = logisticregressionmodel(a,b,c,d, num_iterations=2000, learning_rate=1e-05, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}